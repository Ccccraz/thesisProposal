---
title: "Behaviourally-guided vision: A fully immersive virtual reality study of non-human primate sensory processing"
---

# Proposal background and significance

In the progress made in trying to understand sensory area that process visual infomation, decades of work have elaborated a model in which the main task of sensory area is to integrate classes of data, into invariant representations ([@fig-classSensormotor] *a, b*). This model suggested these discrete "filters" such as lateral geniculate nucleus and primary visual cortical area V1 attempt to provide veridical representations of their local sensory inputs[@carandiniWeKnowWhat2005; @morganFeaturesPrimalSketch2011].This model suggested these discrete "filters" such as lateral geniculate nucleus and primary visual cortical area V1 attempt to provide veridical representations of their local sensory inputs[@carandiniWeKnowWhat2005; @morganFeaturesPrimalSketch2011]. The previous work has shown a substantial range of spatial and temporal effects of feedback[@wangFunctionalAlignmentFeedback2006; @wangFocalGainControl2016a; @andolinaCorticothalamicFeedbackEnhances2007; @andolinaEffectsCorticalFeedback2013; @jonesDifferentialFeedbackModulation2012; @jonesResponsesPrimateLGN2013; @saltPotentiationSensoryResponses2012; @sillitoAlwaysReturningFeedback2006; @gilbertTopdownInfluencesVisual2013; @angelucciCircuitsMechanismsSurround2017]. Recently, there is evidence of incoming sensory infomation not only being modulated by spatio-temporal modulation but also having a board range of high-level extra-classical input to early visual areas. This input enable neurons with focal classic receptive fields to be driven by factors such as the task relevant context of their visual surroundings, saccade, motor activity, other sensory modalities like hearing and and the cognitive demands of ongoing behavioural tasks[@saalmannCognitivePerceptualFunctions2011; @gilbertTopdownInfluencesVisual2013; @petroContributionsCorticalFeedback2014; @fregnacCorticalCorrelatesLowLevel2015; @phillipsFunctionsMechanismsMalfunctions2015]. The implicit assumption of this theory is that in primary visual areas such as V1 the connections from the LGN shoud dominate. However, in real biological networks the numbers of feedforward inputs from senses are numerically dwarfed by intrinsic connections from within the brain itself[@fellemanDistributedHierarchicalProcessing1991a; @markovWeightConsistencySpecifies2011]. This sample fact contradicts the tranditional sensorimotor loop model([@fig-classSensormotor] *a, b*). These conflicts raise new questions and challenges.

:::{#fig-classSensormotor}

![](assets/images/classSensorimotor.png)

In fig a & b there is a classic sensorimotor loop. Environment state [***W~1~***] stimulates sensors and then sensory areas [***S~1~***] processes the input stimulation from sensors and feeds forward to a decision making controller [***C~1~***], which goals is to reliably accumulate evidence for the most "probable" external state [***W~1~***], with which it subsequently guides motor preparation and action [***A~1~***]. This repositions the agent relative to the world and a new loop of activity begins [w~2~→s~2~→c~2~→a~2~] etc.
:::

## Predictive coding

Information theory tells us that information is inseparable from a lack of predictability. If something is predictable before observing it, it cannot give us much information. Conversely, to maximize the rate of information transfer, the message must be minimally predictable and hence minimally redundant. Predictive coding as a means to remove redundancy in a signal was first applied in signal processing, where it was used to reduce transmission bandwidth for video transmission. Predictive coding offers a potentially unifying account of cortical function – postulating that the core function of the brain is to minimize prediction errors with respect to a generative model of the world. The theory is closely related to the Bayesian brain framework and, over the last two decades, has gained substantial influence in the fields of theoretical and cognitive neuroscience. 

## Virtual reality and neuroscience
In order to study the correlation between early sensory cortex and motor or other higher cognitive functions, this poses new requirements for our experimental setup: we need a method that allows for precise recording of brain activity while animals are in a awake and behaving state. As far back as the 1960s, biologists studying movement tethered fruit flies` heads while the insects walked on ping-pong balls. A technical breakthrough came in 2009, when David Tank and colleagues recorded hoppocampal cells intracellularly while a mouse was running on spherical floating ball linked to a virtual reality stimulus generator[@harveyIntracellularDynamicsHippocampal2009]. The technology offered a way to observe brain activity in animals that could be fooled into thinking they were roaming freely, even though their heads were held still. That allowed the use of intricate brain-recording techniques - such as electrical recordings from inside neurons, or optical microscopy to image large numbers of meurons[@drewMouseVideoGame2019]. With combinations of wide-field two-photon and Neuropixel recording the latest studies are conclusive: V~1~ is not a low-level sensory filter, and is strongly driven by motor and other task behaviour[@saleemCoherentEncodingSubjective2018; @devriesLargescaleStandardizedPhysiological2020; @mcbrideLocalGlobalInfluences2019; @musallSingletrialNeuralDynamics2019; @stringerSpontaneousBehaviorsDrive2019]. Particularly for ongoing trial-by-trial variability, motor activity dominates[@musallSingletrialNeuralDynamics2019; @stringerSpontaneousBehaviorsDrive2019]. Georg Keller’s lab has demonstrated how predictive motor task signals are present and fed back from motor to visual areas to substantially alter processing[@attingerVisuomotorCouplingShapes2017; @fiserExperiencedependentSpatialExpectations2016; @zmarzMismatchReceptiveFields2016; @leinweberSensorimotorCircuitMouse2017; @heindorfMouseMotorCortex2018]. They used a variety of visual task designs, such as visual-flow learnging[@attingerVisuomotorCouplingShapes2017], expectation-violation [@zmarzMismatchReceptiveFields2016], and sensory remapping [@leinweberSensorimotorCircuitMouse2017; @heindorfMouseMotorCortex2018] to dissociate incoming visual information from the motor task demands. Combined with these clever sensory dissociations only possible due to VR.

# Development status and trends in this discipline

